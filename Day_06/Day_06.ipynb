{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc98e9b6-12a1-4768-a3bf-418d6eee3534",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Do NOT call mlflow.pyspark.ml.autolog() — crashes on serverless\n",
    "CATALOG = 'ecommerce'\n",
    "print('Imports done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "514ce134-31ae-4f07-8977-e9bf6be589df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow working! Run ID: 4acea46d7f5a4c88915bc7c29aab9921\nCheck left sidebar -> Experiments -> /ecom_purchase_prediction_2\n"
     ]
    }
   ],
   "source": [
    "# MLflow Connectivity Test (Run First)\n",
    "# Always run this first to confirm MLflow is working before you start training.\n",
    "\n",
    "mlflow.set_experiment('/ecom_purchase_prediction_2')\n",
    "\n",
    "with mlflow.start_run(run_name='connectivity_test') as run:\n",
    "    mlflow.log_param('test', 'ok')\n",
    "    mlflow.log_metric('test_metric', 1.0)\n",
    "    print(f'MLflow working! Run ID: {run.info.run_id}')\n",
    "    print('Check left sidebar -> Experiments -> /ecom_purchase_prediction_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51fa22a-196b-43aa-820c-c48c996dd259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All runs deleted from experiment /ecom_purchase_prediction_2.\n"
     ]
    }
   ],
   "source": [
    "# Clear all MLflow experiments (delete all runs in the experiment)\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = mlflow.get_experiment_by_name('/ecom_purchase_prediction_2')\n",
    "if experiment:\n",
    "    runs = client.search_runs(experiment.experiment_id)\n",
    "    for run in runs:\n",
    "        client.delete_run(run.info.run_id)\n",
    "    print('All runs deleted from experiment /ecom_purchase_prediction_2.')\n",
    "else:\n",
    "    print('Experiment not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6bf2d87-5ed2-4ec1-bee9-fbb299c10d8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 4,579,212\nTest rows:  1,142,381\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_events</th><th>total_sessions</th><th>total_views</th><th>total_cart_adds</th><th>avg_price_viewed</th><th>will_purchase</th><th>class_weight</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0.0</td><td>0</td><td>0.5888</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0.0</td><td>0</td><td>0.5888</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0.0</td><td>0</td><td>0.5888</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0.0</td><td>0</td><td>0.5888</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0.0</td><td>0</td><td>0.5888</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         1,
         0,
         1,
         0.0,
         0,
         0.5888
        ],
        [
         1,
         1,
         0,
         1,
         0.0,
         0,
         0.5888
        ],
        [
         1,
         1,
         0,
         1,
         0.0,
         0,
         0.5888
        ],
        [
         1,
         1,
         0,
         1,
         0.0,
         0,
         0.5888
        ],
        [
         1,
         1,
         0,
         1,
         0.0,
         0,
         0.5888
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_events",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_sessions",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_views",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_cart_adds",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_price_viewed",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "will_purchase",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "class_weight",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Data from Day 5\n",
    "df_all   = spark.table(f'{CATALOG}.gold.ml_dataset')\n",
    "df_train = df_all.filter(col('split') == 'train')\n",
    "df_test  = df_all.filter(col('split') == 'test')\n",
    "\n",
    "print(f'Train rows: {df_train.count():,}')\n",
    "print(f'Test rows:  {df_test.count():,}')\n",
    "\n",
    "# 5 numerical features only — avoids the maxBins error from string-encoded categories\n",
    "FEATURE_COLS = [\n",
    "    'total_events', 'total_sessions', 'total_views',\n",
    "    'total_cart_adds', 'avg_price_viewed'\n",
    "]\n",
    "LABEL_COL  = 'will_purchase'\n",
    "WEIGHT_COL = 'class_weight'\n",
    "\n",
    "display(df_train.select(FEATURE_COLS + [LABEL_COL, WEIGHT_COL]).limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817de1e5-66ce-4567-881f-e5ec54757136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Why 5 features only? favourite_brand has 2,414 unique values which causes a RandomForest error (maxBins=32 by default). Keeping only the 5 numerical features avoids this entirely. These 5 features carry the strongest predictive signal anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a0aa6e-3cfa-4e38-b00d-e58b34738d56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluators ready\n"
     ]
    }
   ],
   "source": [
    "# Define Evaluators\n",
    "# Define once, reuse for every model.\n",
    "\n",
    "# AUC — primary metric (correct for imbalanced data)\n",
    "auc_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol         = LABEL_COL,\n",
    "    rawPredictionCol = 'rawPrediction',\n",
    "    metricName       = 'areaUnderROC'\n",
    ")\n",
    "\n",
    "# F1 — secondary metric\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol      = LABEL_COL,\n",
    "    predictionCol = 'prediction',\n",
    "    metricName    = 'f1'\n",
    ")\n",
    "print('Evaluators ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5daeefeb-21c4-4feb-b078-521877884ff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\nDone!\nLogistic Regression -> AUC: 0.9125  |  F1: 0.8901\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "# Logistic Regression needs StandardScaler because our features have very different ranges (total_events mean=22, avg_price_viewed mean=307). Without scaling, the model gets confused by the magnitude difference.\n",
    "\n",
    "# Step 1: Combine all features into one vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols     = FEATURE_COLS,\n",
    "    outputCol     = 'features_raw',\n",
    "    handleInvalid = 'skip'\n",
    ")\n",
    "\n",
    "# Step 2: Scale features to same range (required for Logistic Regression)\n",
    "scaler = StandardScaler(\n",
    "    inputCol  = 'features_raw',\n",
    "    outputCol = 'features',\n",
    "    withMean  = True,\n",
    "    withStd   = True\n",
    ")\n",
    "\n",
    "# Step 3: Define model\n",
    "lr = LogisticRegression(\n",
    "    featuresCol = 'features',\n",
    "    labelCol    = LABEL_COL,\n",
    "    weightCol   = WEIGHT_COL,   # class weights from Day 5\n",
    "    maxIter     = 100,\n",
    "    regParam    = 0.01          # small regularisation to prevent overfitting\n",
    ")\n",
    "\n",
    "# Chain all steps into one pipeline\n",
    "lr_pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "\n",
    "# Train with MLflow tracking\n",
    "with mlflow.start_run(run_name='logistic_regression') as run:\n",
    "    mlflow.log_param('model',    'LogisticRegression')\n",
    "    mlflow.log_param('maxIter',  100)\n",
    "    mlflow.log_param('regParam', 0.01)\n",
    "    mlflow.log_param('features', str(FEATURE_COLS))\n",
    "\n",
    "    print('Training Logistic Regression...')\n",
    "    lr_model = lr_pipeline.fit(df_train)\n",
    "    print('Done!')\n",
    "\n",
    "    lr_preds = lr_model.transform(df_test)\n",
    "    lr_auc   = auc_evaluator.evaluate(lr_preds)\n",
    "    lr_f1    = f1_evaluator.evaluate(lr_preds)\n",
    "\n",
    "    mlflow.log_metric('test_auc', lr_auc)\n",
    "    mlflow.log_metric('test_f1',  lr_f1)\n",
    "\n",
    "    lr_run_id = run.info.run_id\n",
    "    print(f'Logistic Regression -> AUC: {lr_auc:.4f}  |  F1: {lr_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9605bd15-96c5-4c44-bcd5-a24298f03c81",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inspect Logistic Regression Results"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>will_purchase</th><th>prediction</th><th>probability</th><th>total_events</th><th>total_cart_adds</th></tr></thead><tbody><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr><tr><td>0</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ],
        [
         0,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6193027973883906\",\"0.38069720261160944\"]}",
         1,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "will_purchase",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"ml_attr\": {\"num_vals\": 2, \"type\": \"nominal\"}}",
         "name": "prediction",
         "type": "\"double\""
        },
        {
         "metadata": "{\"ml_attr\": {\"num_attrs\": 2}}",
         "name": "probability",
         "type": "{\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"fields\":[{\"metadata\":{},\"name\":\"type\",\"nullable\":false,\"type\":\"byte\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"indices\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"integer\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"values\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"double\",\"type\":\"array\"}}],\"type\":\"struct\"},\"type\":\"udt\"}"
        },
        {
         "metadata": "{}",
         "name": "total_events",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_cart_adds",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFUSION MATRIX ===\n+-------------+----------+------+\n|will_purchase|prediction| count|\n+-------------+----------+------+\n|            0|       0.0|893473|\n|            0|       1.0| 76826|\n|            1|       0.0| 52234|\n|            1|       1.0|119848|\n+-------------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Inspect Logistic Regression Results\n",
    "# See sample predictions\n",
    "display(\n",
    "    lr_preds.select('will_purchase', 'prediction', 'probability',\n",
    "                    'total_events', 'total_cart_adds').limit(10)\n",
    ")\n",
    "\n",
    "# Confusion matrix — how many did the model get right vs wrong\n",
    "print('=== CONFUSION MATRIX ===')\n",
    "lr_preds.groupBy('will_purchase', 'prediction') \\\n",
    "    .count() \\\n",
    "    .orderBy('will_purchase', 'prediction') \\\n",
    "    .show()\n",
    "\n",
    "# will_purchase=1, prediction=1 -> correctly predicted buyer     (True Positive)\n",
    "# will_purchase=1, prediction=0 -> missed a buyer                (False Negative)\n",
    "# will_purchase=0, prediction=1 -> wrongly predicted buyer       (False Positive)\n",
    "# will_purchase=0, prediction=0 -> correctly predicted non-buyer (True Negative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3d0a2fe-2dc8-4c20-b0a7-2ab9a1a0b991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train Random Forest\n",
    "Random Forest does NOT need StandardScaler. Trees split on feature value thresholds — the actual scale does not matter. We also use only 5 numerical features to avoid the maxBins error that occurs with string-encoded categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de1b3808-306b-4f5d-9021-65e8fd485581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest (takes longer than LR)...\nDone!\nRandom Forest -> AUC: 0.9438  |  F1: 0.8829\n"
     ]
    }
   ],
   "source": [
    "# For RF: VectorAssembler only — no scaler needed\n",
    "assembler_rf = VectorAssembler(\n",
    "    inputCols     = FEATURE_COLS,\n",
    "    outputCol     = 'features',       # RF reads from 'features' directly\n",
    "    handleInvalid = 'skip'\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol = 'features',\n",
    "    labelCol    = LABEL_COL,\n",
    "    weightCol   = WEIGHT_COL,\n",
    "    numTrees    = 50,                 # 50 trees — good balance of speed vs accuracy\n",
    "    maxDepth    = 5,                  # keep shallow to avoid overfitting\n",
    "    seed        = 42                  # fixed seed = reproducible results\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[assembler_rf, rf])\n",
    "\n",
    "with mlflow.start_run(run_name='random_forest') as run:\n",
    "    mlflow.log_param('model',    'RandomForest')\n",
    "    mlflow.log_param('numTrees', 50)\n",
    "    mlflow.log_param('maxDepth', 5)\n",
    "    mlflow.log_param('features', str(FEATURE_COLS))\n",
    "\n",
    "    print('Training Random Forest (takes longer than LR)...')\n",
    "    rf_model = rf_pipeline.fit(df_train)\n",
    "    print('Done!')\n",
    "\n",
    "    rf_preds = rf_model.transform(df_test)\n",
    "    rf_auc   = auc_evaluator.evaluate(rf_preds)\n",
    "    rf_f1    = f1_evaluator.evaluate(rf_preds)\n",
    "\n",
    "    mlflow.log_metric('test_auc', rf_auc)\n",
    "    mlflow.log_metric('test_f1',  rf_f1)\n",
    "\n",
    "    rf_run_id = run.info.run_id\n",
    "    print(f'Random Forest -> AUC: {rf_auc:.4f}  |  F1: {rf_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ebeec6-d892-48a3-8cdb-3c01d2e3d4ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Feature Importances (Random Forest)\n",
    "Random Forest tells you which features contributed most to its predictions — for free, after training. This helps you understand what actually drives purchase behaviour in your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d460dc38-95eb-4953-a2c0-32a98b6d9fb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE IMPORTANCES ===\nFeature                   Importance\n--------------------------------------\ntotal_cart_adds               0.6783  ########################################\ntotal_events                  0.2173  #############\ntotal_sessions                0.0600  ###\ntotal_views                   0.0428  ##\navg_price_viewed              0.0016  \n"
     ]
    }
   ],
   "source": [
    "rf_fitted = rf_model.stages[-1]   # last stage of the pipeline = the RF model\n",
    "\n",
    "importances = list(zip(FEATURE_COLS, rf_fitted.featureImportances))\n",
    "importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('=== FEATURE IMPORTANCES ===')\n",
    "print(f'{\"Feature\":<25} {\"Importance\":>10}')\n",
    "print('-' * 38)\n",
    "for feat, imp in importances:\n",
    "    bar = '#' * int(imp * 60)\n",
    "    print(f'{feat:<25} {imp:>10.4f}  {bar}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "358f6e0a-cefa-4729-97f8-d0f1b18abd0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Tune Random Forest (Try Better Parameters)\n",
    "Tuning means trying different settings to see if we can improve AUC. We try numTrees=20 vs 100 and maxDepth=5 vs 10. Each combination trains a separate model and logs its AUC to MLflow so you can compare.\n",
    "\n",
    "> This is simple manual tuning — not CrossValidator. We train each combination separately and log it as its own MLflow run. Easy to understand, easy to debug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2928b167-df09-46aa-be96-0d12e5c8139a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: numTrees=20 maxDepth=5...\n  AUC: 0.9444  |  F1: 0.8804\nTraining: numTrees=20 maxDepth=10...\n  AUC: 0.9648  |  F1: 0.9025\nTraining: numTrees=100 maxDepth=5...\n  AUC: 0.9441  |  F1: 0.8821\nTraining: numTrees=100 maxDepth=10...\n  AUC: 0.9657  |  F1: 0.9064\n\nBest params: {'numTrees': 100, 'maxDepth': 10}\nBest AUC:    0.9657\nBest run ID: f98d8dd38638437ab739745f6547db73\n"
     ]
    }
   ],
   "source": [
    "# Define the combinations you want to try\n",
    "param_combos = [\n",
    "    {'numTrees': 20,  'maxDepth': 5},\n",
    "    {'numTrees': 20,  'maxDepth': 10},\n",
    "    {'numTrees': 100, 'maxDepth': 5},\n",
    "    {'numTrees': 100, 'maxDepth': 10},\n",
    "]\n",
    "\n",
    "best_auc       = 0\n",
    "best_params    = None\n",
    "best_run_id    = None\n",
    "\n",
    "for params in param_combos:\n",
    "    run_name = f'rf_trees{params[\"numTrees\"]}_depth{params[\"maxDepth\"]}'\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        mlflow.log_param('model',    'RandomForest')\n",
    "        mlflow.log_param('numTrees', params['numTrees'])\n",
    "        mlflow.log_param('maxDepth', params['maxDepth'])\n",
    "\n",
    "        rf_tune = RandomForestClassifier(\n",
    "            featuresCol = 'features',\n",
    "            labelCol    = LABEL_COL,\n",
    "            weightCol   = WEIGHT_COL,\n",
    "            numTrees    = params['numTrees'],\n",
    "            maxDepth    = params['maxDepth'],\n",
    "            seed        = 42\n",
    "        )\n",
    "        pipeline_tune = Pipeline(stages=[assembler_rf, rf_tune])\n",
    "\n",
    "        print(f'Training: numTrees={params[\"numTrees\"]} maxDepth={params[\"maxDepth\"]}...')\n",
    "        model_tune  = pipeline_tune.fit(df_train)\n",
    "        preds_tune  = model_tune.transform(df_test)\n",
    "        auc_tune    = auc_evaluator.evaluate(preds_tune)\n",
    "        f1_tune     = f1_evaluator.evaluate(preds_tune)\n",
    "\n",
    "        mlflow.log_metric('test_auc', auc_tune)\n",
    "        mlflow.log_metric('test_f1',  f1_tune)\n",
    "\n",
    "        print(f'  AUC: {auc_tune:.4f}  |  F1: {f1_tune:.4f}')\n",
    "\n",
    "        if auc_tune > best_auc:\n",
    "            best_auc    = auc_tune\n",
    "            best_params = params\n",
    "            best_run_id = run.info.run_id\n",
    "\n",
    "print(f'\\nBest params: {best_params}')\n",
    "print(f'Best AUC:    {best_auc:.4f}')\n",
    "print(f'Best run ID: {best_run_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af872371-d036-4177-93df-3d53f9e62d81",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Final Comparison"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\nDAY 6 — MODEL COMPARISON SUMMARY\n=======================================================\nModel                                    AUC       F1\n-------------------------------------------------------\nLogistic Regression                   0.9125   0.8901\nRandom Forest (numTrees=50, depth=5)   0.9438   0.8829\nBest Tuned RF ({'numTrees': 100, 'maxDepth': 10})   0.9657\n=======================================================\n\nWinner: Random Forest (tuned)\nBest AUC: 0.9657\nThis model gets registered in MLflow Model Registry on Day 7.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('=' * 55)\n",
    "print('DAY 6 — MODEL COMPARISON SUMMARY')\n",
    "print('=' * 55)\n",
    "print(f'{\"Model\":<35} {\"AUC\":>8} {\"F1\":>8}')\n",
    "print('-' * 55)\n",
    "print(f'{\"Logistic Regression\":<35} {lr_auc:>8.4f} {lr_f1:>8.4f}')\n",
    "print(f'{\"Random Forest (numTrees=50, depth=5)\":<35} {rf_auc:>8.4f} {rf_f1:>8.4f}')\n",
    "print(f'{\"Best Tuned RF (\" + str(best_params) + \")\":<35} {best_auc:>8.4f}')\n",
    "print('=' * 55)\n",
    "print(f'\\nWinner: Random Forest (tuned)')\n",
    "print(f'Best AUC: {best_auc:.4f}')\n",
    "print('This model gets registered in MLflow Model Registry on Day 7.')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day_06",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}